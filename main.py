



import os
import time
import requests
from dotenv import load_dotenv
from langchain_community.document_loaders import DirectoryLoader, UnstructuredFileLoader
from langchain_community.vectorstores import FAISS
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.chains.combine_documents import create_stuff_documents_chain
from langchain.chains import create_retrieval_chain, create_history_aware_retriever
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.messages import AIMessage, HumanMessage
from redis_state import set_conversation_state_from_bot, get_conversation_state_from_bot, STATE_HUMANO

# Cargar variables de entorno. Aseg√∫rate de tener un archivo .env con tu OPENAI_API_KEY
load_dotenv(override=True)

# --- Constantes ---     
DOCUMENTS_PATH = "documents"
VECTORSTORE_PATH = "vectorstore"
CHUNK_SIZE = 800
CHUNK_OVERLAP = 80
OPENAI_MODEL = "gpt-4o-mini"
PAYMENT_FORM_URL = "https://forms.gle/vBDAguF19cSaDhAK6"
CALENDAR_LINK = "https://n9.cl/fa5tz3"

# --- Configuraci√≥n para estado "escribiendo" ---
BOT_TYPING_DELAY = 15  # segundos
EVO_API_URL = os.getenv('EVO_API_URL', 'http://localhost:8080')
EVO_APIKEY = os.getenv('EVO_APIKEY', '')
EVO_INSTANCE = os.getenv('EVO_INSTANCE', '')

# --- Estados de Conversaci√≥n ---
class ConversationState:
    AWAITING_GREETING = "AWAITING_GREETING"
    AWAITING_NAME_CITY = "AWAITING_NAME_CITY"
    AWAITING_ROLE_INPUT = "AWAITING_ROLE_INPUT"
    AWAITING_SERVICE_CHOICE = "AWAITING_SERVICE_CHOICE"
    AWAITING_CONTINUE_CHOICE = "AWAITING_CONTINUE_CHOICE"
    PROVIDING_INFO = "PROVIDING_INFO"

# --- Funciones Auxiliares para Estado "Escribiendo" ---
def _auth_headers():
    """Devuelve headers de autenticaci√≥n para Evolution API."""
    return {
        'Content-Type': 'application/json',
        'apikey': EVO_APIKEY
    }

def send_typing_indicator(number: str) -> bool:
    """Env√≠a indicador de 'escribiendo...' a WhatsApp."""
    try:
        url = f"{EVO_API_URL}/chat/presence/{EVO_INSTANCE}"
        payload = {
            "number": number,
            "presence": "composing"  # 'composing' = escribiendo
        }
        
        print(f"[TYPING] Enviando indicador 'escribiendo' a {number}")
        response = requests.post(url, headers=_auth_headers(), json=payload, timeout=10)
        
        if response.status_code in (200, 201):
            print(f"[TYPING] ‚úÖ Indicador enviado exitosamente")
            return True
        else:
            print(f"[TYPING] ‚ùå Error al enviar indicador: {response.status_code}")
            return False
            
    except Exception as e:
        print(f"[TYPING ERROR] No se pudo enviar indicador de escritura: {e}")
        return False

def simulate_typing_delay(number: str, delay_seconds: int = BOT_TYPING_DELAY):
    """Simula que el bot est√° escribiendo por un tiempo determinado."""
    try:
        print(f"[TYPING] Iniciando simulaci√≥n de escritura por {delay_seconds} segundos...")
        
        # Enviar indicador de 'escribiendo'
        send_typing_indicator(number)
        
        # Esperar el tiempo especificado
        time.sleep(delay_seconds)
        
        print(f"[TYPING] ‚úÖ Simulaci√≥n de escritura completada")
        
    except Exception as e:
        print(f"[TYPING ERROR] Error durante simulaci√≥n de escritura: {e}")

# --- L√≥gica del Chatbot ---
class Chatbot:
    def __init__(self, vectorstore, chat_id=None):
        self.state = ConversationState.AWAITING_GREETING
        self.user_data = {}
        self.user_data['name'] = "" # Se inicializa el nombre del usuario
        self.chat_history = []
        self.chat_id = chat_id  # Identificador del chat para Redis
        # Sistema de memoria para confirmaciones de pasos
        self.confirmed_steps = {
            'paso1': False,  # Formulario completado
            'paso3': False   # Pago realizado
        }
        self.llm = ChatOpenAI(model_name=OPENAI_MODEL, max_tokens=500, temperature=0.1)
        
        system_prompt = """
        Actu√°s como Xtalento Bot, un asistente profesional c√°lido, claro y experto que gu√≠a a personas a potenciar su perfil laboral y encontrar empleo m√°s r√°pido.
        El nombre del usuario es {user_name}. Cuando sea natural y amigable, utiliza su nombre para personalizar la conversaci√≥n. Si no sabes el nombre (porque est√° vac√≠o), no intentes inventarlo.
        Importante: No utilices la palabra 'Hola' en ninguna de tus respuestas, ya que el saludo inicial ya fue dado. siempre trata de no sobrepasar los 200 tokens.

        üîé Cuando el usuario mencione un servicio, responde incluyendo:
        - Qu√© incluye el servicio.
        - Cu√°l es el precio para su nivel de cargo.
        - C√≥mo se agenda o paga.

        üìå Cuando el usuario mencione su cargo o el √∫ltimo empleo:
        - Clasificalo autom√°ticamente seg√∫n la gu√≠a de cargos (operativo, t√°ctico o estrat√©gico).
        - Usa esa clasificaci√≥n para sugerir servicios y precios.

        üéØ Siempre destac√°:
        - La mentor√≠a virtual personalizada (45 a 60 minutos).
        - La entrega r√°pida (40 a 120 minutos en optimizaci√≥n HV).
        - La garant√≠a de superar filtros ATS.
        - El respaldo de casos reales y experiencia.

        üö® POL√çTICA DE CONOCIMIENTO ESTRICTA:
        - SOLO habla de lo que tienes conocimiento confirmado en el contexto proporcionado (RAG).
        - NO inventes informaci√≥n, servicios, precios o datos que no est√©n en tu base de conocimiento.
        - Si no tienes conocimiento suficiente sobre algo que te preguntan, responde honestamente: "Actualmente no tengo conocimiento sobre esto. Si quieres comunicarte con un humano, menciona la palabra 'agente' en el chat."
        - Si el usuario menciona "agente" en cualquier momento, conecta inmediatamente con un agente humano.
        - Si el usuario decide seguir con el bot despu√©s de no tener informaci√≥n, tu objetivo principal es vender un servicio disponible en tu conocimiento y proponer agendar una sesi√≥n virtual.
        - Usa emojis con calidez, sin perder profesionalismo. S√© concreto y con orientaci√≥n clara a la acci√≥n.
        """
        
        retriever = vectorstore.as_retriever()

        contextualize_q_system_prompt = """Dada una conversaci√≥n y una pregunta de seguimiento, reformula la pregunta de seguimiento para que sea una pregunta independiente, en su idioma original. El nombre del usuario es {user_name}. IMPORTANTE: Solo utiliza informaci√≥n que est√© confirmada en el contexto de la conversaci√≥n. Si no tienes conocimiento suficiente, indica que no tienes esa informaci√≥n y que el cliente se puede comunicar con un agente humano. copiando la palabra agente en el chat"""
        contextualize_q_prompt = ChatPromptTemplate.from_messages(
            [
                ("system", contextualize_q_system_prompt),
                MessagesPlaceholder(variable_name="chat_history"),
                ("human", "{input}"),
            ]
        )
        history_aware_retriever = create_history_aware_retriever(
            self.llm, retriever, contextualize_q_prompt
        )

        qa_system_prompt = system_prompt + """

        Contexto: {context}
        Respuesta:"""
        qa_prompt = ChatPromptTemplate.from_messages(
            [
                ("system", qa_system_prompt),
                MessagesPlaceholder(variable_name="chat_history"),
                ("human", "{input}"),
            ]
        )
        question_answer_chain = create_stuff_documents_chain(self.llm, qa_prompt)

        self.rag_chain = create_retrieval_chain(history_aware_retriever, question_answer_chain)
    
    def _apply_typing_delay(self, user_number: str = None):
        """Aplica retraso con indicador de escritura si hay un n√∫mero de usuario disponible."""
        if user_number and EVO_API_URL and EVO_APIKEY and EVO_INSTANCE:
            simulate_typing_delay(user_number, BOT_TYPING_DELAY)
        else:
            # Si no hay configuraci√≥n de API, simplemente esperar sin indicador
            print(f"[TYPING] API no configurada, aplicando solo retraso de {BOT_TYPING_DELAY}s")
            time.sleep(BOT_TYPING_DELAY)

    def _extract_role_from_text(self, text):
        """Extrae el cargo o rol laboral de un texto complejo."""
        extraction_prompt = f"""
        Analiza el siguiente texto y extrae √öNICAMENTE el cargo o rol laboral mencionado. 

        Ejemplos:
        - "Estoy desempleado antes era analista de datos" ‚Üí "analista de datos"
        - "Soy gerente de ventas en una empresa" ‚Üí "gerente de ventas"
        - "Trabajo como desarrollador frontend" ‚Üí "desarrollador frontend"
        - "Fui coordinador de proyectos" ‚Üí "coordinador de proyectos"
        - "Me desempe√±o como CEO" ‚Üí "CEO"
        - "Quiero trabajar de marketing" ‚Üí "marketing"

        IMPORTANTE: 
        - Extrae solo el cargo/rol, sin contexto adicional
        - Si hay m√∫ltiples cargos, extrae el m√°s relevante o reciente
        - Si no hay un cargo claro, responde 'no_identificable'
        - No agregues explicaciones

        Texto: "{text}"
        Cargo extra√≠do:
        """
        response = self.llm.invoke(extraction_prompt)
        extracted_role = response.content.strip()
        
        if extracted_role.lower() in ['no_identificable', 'no identificable', '']:
            return None
        return extracted_role

    def _classify_role(self, role_description):
        """Usa el LLM para extraer y clasificar un rol de texto complejo en operativo, t√°ctico o estrat√©gico."""
        # Paso 1: Extraer el cargo del texto complejo
        extracted_role = self._extract_role_from_text(role_description)
        
        if not extracted_role:
            print(f"[DEBUG] No se pudo extraer un cargo del texto: {role_description}")
            return None
            
        print(f"[DEBUG] Cargo extra√≠do: '{extracted_role}' del texto: '{role_description}'")
        
        # Paso 2: Clasificar el cargo extra√≠do
        classification_prompt_text = f"""
        Clasifica el siguiente cargo laboral en UNO de estos tres niveles jer√°rquicos.
        Responde √öNICAMENTE con la palabra: operativo, t√°ctico o estrat√©gico.

        NIVELES JER√ÅRQUICOS:

        OPERATIVO: Cargos de ejecuci√≥n directa y t√©cnicos
        - Analistas, desarrolladores, asistentes, operarios, t√©cnicos
        - Especialistas junior, consultores junior
        - Ejecutivos de cuenta, vendedores

        T√ÅCTICO: Cargos de supervisi√≥n y coordinaci√≥n media
        - Coordinadores, especialistas senior, jefes de √°rea
        - Supervisores, team leads, l√≠deres de equipo
        - Gerentes de √°rea espec√≠fica

        ESTRAT√âGICO: Cargos de alta direcci√≥n y toma de decisiones
        - CEO, presidente, vicepresidente, director general
        - Directores de √°rea, gerentes generales
        - VP (vicepresidente), fundadores

        Cargo a clasificar: "{extracted_role}"

        Respuesta (solo la palabra):"""
        response = self.llm.invoke(classification_prompt_text)
        # Aseguramos que la respuesta sea una de las tres opciones v√°lidas
        classification_raw = response.content.strip().lower()
        
        print(f"[DEBUG] Clasificaci√≥n raw obtenida: '{classification_raw}' para cargo: '{extracted_role}'")
        
        # Extraer la clasificaci√≥n real del texto (por si el LLM agrega palabras extra)
        if 'operativo' in classification_raw:
            classification = 'operativo'
        elif 't√°ctico' in classification_raw or 'tactico' in classification_raw:
            classification = 't√°ctico'
        elif 'estrat√©gico' in classification_raw or 'estrategico' in classification_raw:
            classification = 'estrat√©gico'
        else:
            print(f"[DEBUG] No se pudo extraer clasificaci√≥n v√°lida de: '{classification_raw}'")
            return None
        
        print(f"[DEBUG] Clasificaci√≥n final: '{classification}' para cargo: '{extracted_role}'")
        return classification

    def _extract_name(self, name_city_text):
        """Usa el LLM para extraer el nombre de pila del usuario de un texto."""
        extraction_prompt_text = f"""
        De la siguiente frase, extrae √∫nicamente el nombre de pila del usuario.
        Ejemplo: si la frase es "Soy Carlos de Lima", la respuesta debe ser "Carlos".
        IMPORTANTE: Solo extrae el nombre si est√° claramente presente. Si no puedes identificar un nombre con certeza, responde 'no_identificable'.
        Devuelve solo el nombre, sin explicaciones ni texto adicional.
        Frase: "{name_city_text}"
        Nombre de pila:
        """
        response = self.llm.invoke(extraction_prompt_text)
        name = response.content.strip()
        
        # Si el LLM no devuelve nada, usamos la primera palabra como fallback.
        if not name:
            return name_city_text.split()[0]
        return name

    def _generate_response(self, prompt_text):
        """Genera una respuesta directa del LLM para mensajes conversacionales."""
        # Usamos el mismo LLM pero sin el contexto de RAG
        response = self.llm.invoke(prompt_text)
        return response.content.strip()

    def _safe_rag_answer(self, query_text: str) -> str:
        """Intenta responder v√≠a RAG; si falla, contin√∫a la conversaci√≥n con conocimiento general (LLM)."""
        try:
            response = self.rag_chain.invoke({"input": query_text, "chat_history": self.chat_history, "user_name": self.user_data.get('name', '')})
            answer_text = response.get('answer') or ""
            if not answer_text.strip():
                return self._build_unknown_options_message()
            return answer_text
        except Exception:
            return self._build_unknown_options_message()

    def _build_unknown_options_message(self) -> str:
        """Devuelve el mensaje est√°ndar de opciones cuando no hay suficiente informaci√≥n."""
        return (
            "Actualmente no tengo conocimiento sobre esto. Si quieres comunicarte con un humano, menciona la palabra 'agente' en el chat. "
            "¬øQu√© prefieres que hagamos?\n\n"
            "1) Hablar con un agente humano (menciona 'agente' para conectarte inmediatamente).\n"
            "2) Seguir conmigo y explorar otros servicios de Xtalento que s√≠ conozco."
        )

    def _continue_conversation(self, user_text: str, guidance: str) -> str:
        """Responde cuando no se detecta una respuesta v√°lida, ofreciendo opciones claras al usuario."""
        return (
            "No se detect√≥ una respuesta v√°lida. "
            "¬øQu√© prefieres?\n\n"
            "1) Te remito con un agente de ventas humano\n"
            "2) Seguir hablando conmigo\n\n"
            "Si quieres hablar con un agente, escribe 'agente'."
        )
    
    def _is_agent_request(self, user_input: str) -> bool:
        """Detecta si el usuario est√° solicitando espec√≠ficamente un agente humano."""
        text = user_input.lower().strip()
        words = text.split()
        
        # Caso 1: Palabra exacta "agente"
        if len(words) == 1 and words[0] == 'agente':
            return True
            
        # Caso 2: Frases espec√≠ficas de solicitud de agente
        agent_request_phrases = [
            'Quiero un agente', 'Necesito un agente', 'Conectame con un agente',
            'Hablar con un agente', 'Contactar un agente', 'Agente humano',
            'Quiero agente', 'Necesito agente', 'Conectame con agente',
            'Quiero hablar con un agente', 'Necesito hablar con un agente'
        ]
        
        return any(phrase in text for phrase in agent_request_phrases)

    def _is_returning_after_agent(self, user_input: str) -> bool:
        """Detecta si el cliente est√° retomando la conversaci√≥n despu√©s de haber hablado con un agente humano."""
        try:
            prompt = f"""
            Analiza si el siguiente mensaje parece ser de un cliente que est√° retomando o continuando una conversaci√≥n despu√©s de haber hablado con un agente humano.

            MENSAJE DEL USUARIO: "{user_input}"

            ¬øEste mensaje indica que el cliente est√° retomando la conversaci√≥n o necesita m√°s ayuda?

            Responde √öNICAMENTE:
            - "S√ç" si parece que retoma conversaci√≥n, saluda de nuevo, o busca m√°s ayuda
            - "NO" si es una respuesta espec√≠fica a opciones del bot

            Indicadores de retomar conversaci√≥n:
            - Saludos nuevos: "Hola", "Buenos d√≠as", "Qu√© tal"
            - Frases de continuaci√≥n: "Necesito m√°s informaci√≥n", "Tengo otra pregunta"
            - Agradecimientos y nuevas consultas: "Gracias, pero tambi√©n quer√≠a..."
            - Mensajes naturales que no son respuestas a opciones espec√≠ficas

            Ejemplos:
            - "Hola, tengo una pregunta adicional" ‚Üí S√ç
            - "Buenos d√≠as, necesito m√°s informaci√≥n" ‚Üí S√ç  
            - "Gracias por la atenci√≥n, pero quer√≠a saber..." ‚Üí S√ç
            - "¬øTienen otros servicios?" ‚Üí S√ç
            - "1" ‚Üí NO (respuesta a opci√≥n)
            - "agente" ‚Üí NO (solicitud espec√≠fica)
            """
            
            response = self.llm.invoke(prompt).content.strip().upper()
            
            if "S√ç" in response or "SI" in response:
                print(f"[DEBUG] LLM detect√≥ cliente retomando conversaci√≥n: {response}")
                return True
            else:
                print(f"[DEBUG] LLM NO detect√≥ retomar conversaci√≥n: {response}")
                return False
                
        except Exception as e:
            print(f"[ERROR] Error en _is_returning_after_agent: {e}")
            # Fallback: detectar saludos b√°sicos y frases de retomar
            return any(phrase in user_input.lower() for phrase in [
                'hola', 'buenos d√≠as', 'buenas tardes', 'qu√© tal', 'necesito m√°s', 'tengo otra', 'quer√≠a saber'
            ])

    def _generate_welcome_back_message(self, user_input: str) -> str:
        """Genera un mensaje de bienvenida c√°lido para clientes que retoman la conversaci√≥n."""
        user_name = self.user_data.get('name', '')
        name_part = f"{user_name}, " if user_name and user_name != 'no_identificable' else ""
        
        try:
            prompt = f"""
            Genera un mensaje de bienvenida c√°lido y profesional para un cliente que est√° retomando la conversaci√≥n con Xtalento Bot despu√©s de haber hablado con un agente humano.

            NOMBRE DEL CLIENTE: {name_part}
            MENSAJE DEL CLIENTE: "{user_input}"

            El mensaje debe:
            1. Dar la bienvenida de vuelta de forma c√°lida
            2. Agradecer por su regreso
            3. Preguntar en qu√© podemos ayudarle
            4. Ser profesional pero amigable
            5. Usar el nombre si est√° disponible
            6. M√°ximo 150 palabras

            Ejemplos de tono:
            - "¬°{name_part}es un gusto tenerte de vuelta! Agradezco que regreses a conversar conmigo..."
            - "¬°Qu√© bueno verte de nuevo{name_part}! Me da mucho gusto que hayas decidido continuar..."

            Genera el mensaje de bienvenida:
            """
            
            response = self.llm.invoke(prompt).content.strip()
            return response
            
        except Exception as e:
            print(f"[ERROR] Error en _generate_welcome_back_message: {e}")
            # Fallback mensaje est√°tico
            return f"¬°{name_part}es un gusto tenerte de vuelta! üòä Agradezco que regreses a conversar conmigo. Me da mucho gusto que hayas decidido continuar con nuestros servicios. ¬øEn qu√© m√°s puedo ayudarte hoy?"

    def _is_natural_conversation_resumption(self, user_input: str) -> bool:
        """Detecta si el usuario est√° retomando una conversaci√≥n de forma natural."""
        try:
            prompt = f"""
            Analiza si el siguiente mensaje parece ser una conversaci√≥n natural donde alguien est√°:
            - Saludando normalmente
            - Haciendo una pregunta sobre servicios laborales
            - Retomando una conversaci√≥n previa
            - Escribiendo algo natural (no solo n√∫meros o palabras clave)

            MENSAJE: "{user_input}"

            ¬øEste mensaje parece una conversaci√≥n natural que deber√≠a ser respondida normalmente?

            Responde √öNICAMENTE:
            - "S√ç" si es conversaci√≥n natural
            - "NO" si parece ser respuesta a opciones espec√≠ficas (1, 2, agente, etc.)

            Ejemplos:
            - "Hola estoy haciendo pruebas" ‚Üí S√ç
            - "¬øQu√© servicios tienen?" ‚Üí S√ç
            - "Me interesa mejorar mi CV" ‚Üí S√ç
            - "1" ‚Üí NO
            - "agente" ‚Üí NO
            - "seguir hablando" ‚Üí NO
            """
            
            response = self.llm.invoke(prompt).content.strip().upper()
            
            if "S√ç" in response or "SI" in response:
                print(f"[DEBUG] LLM detect√≥ conversaci√≥n natural: {response}")
                return True
            else:
                print(f"[DEBUG] LLM detect√≥ respuesta espec√≠fica: {response}")
                return False
                
        except Exception as e:
            print(f"[ERROR] Error en _is_natural_conversation_resumption: {e}")
            # Fallback: si tiene m√°s de 10 caracteres y no son n√∫meros, probablemente es natural
            return len(user_input.strip()) > 10 and not user_input.strip().isdigit()

    def _detect_service_intention(self, user_input: str) -> bool:
        """Usa LLM para detectar si el usuario quiere seleccionar un servicio espec√≠fico."""
        try:
            prompt = f"""
            Analiza si el siguiente mensaje del usuario indica que quiere seleccionar UN SERVICIO ESPEC√çFICO de esta lista:

            SERVICIOS DISPONIBLES:
            1. Optimizaci√≥n de Hoja de vida (ATS)
            2. Mejora de perfil en plataformas de empleo  
            3. Preparaci√≥n para Entrevistas
            4. Estrategia de b√∫squeda de empleo
            5. Simulaci√≥n de entrevista con feedback
            6. M√©todo X (servicio premium)
            7. Test EPI - Evaluaci√≥n de Personalidad Integral
            8. Todos los servicios

            MENSAJE DEL USUARIO: "{user_input}"

            ¬øEl usuario est√° intentando seleccionar un servicio espec√≠fico de la lista?

            Responde √öNICAMENTE:
            - "S√ç" si claramente quiere un servicio espec√≠fico (n√∫meros, nombres, o intenci√≥n clara)
            - "NO" si es una pregunta general, saludo, o no menciona servicios espec√≠ficos

            Ejemplos:
            - "Quiero el 3" ‚Üí S√ç
            - "Hoja de vida" ‚Üí S√ç  
            - "¬øQu√© incluye el m√©todo X?" ‚Üí NO (es pregunta, no selecci√≥n)
            - "Hola, estoy interesado" ‚Üí NO (muy general)
            - "Todos" ‚Üí S√ç
            """
            
            response = self.llm.invoke(prompt).content.strip().upper()
            
            # Si dice S√ç, el usuario quiere seleccionar un servicio
            if "S√ç" in response or "SI" in response:
                print(f"[DEBUG] LLM detect√≥ intenci√≥n de servicio: {response}")
                return True
            else:
                print(f"[DEBUG] LLM NO detect√≥ selecci√≥n de servicio: {response}")
                return False
                
        except Exception as e:
            print(f"[ERROR] Error en _detect_service_intention: {e}")
            # Fallback a detecci√≥n b√°sica por keywords
            service_keywords = ['1', '2', '3', '4', '5', '6', '7', '8', 'todos', 'todo', 'hoja de vida', 'cv', 'm√©todo x', 'metodo x']
            return any(keyword in user_input.lower() for keyword in service_keywords)

    def _detect_scheduling_request(self, user_input: str) -> bool:
        """Usa LLM para detectar si el usuario quiere agendar una cita o sesi√≥n."""
        try:
            prompt = f"""
            Analiza si el siguiente mensaje del usuario indica que quiere AGENDAR, PROGRAMAR o SOLICITAR una cita, sesi√≥n, reuni√≥n o consulta.

            MENSAJE DEL USUARIO: "{user_input}"

            ¬øEl usuario est√° intentando agendar o programar algo?

            Responde √öNICAMENTE:
            - "S√ç" si claramente quiere agendar, programar o solicitar una cita/sesi√≥n
            - "NO" si solo est√° preguntando sobre horarios, precios, o haciendo consultas generales

            Ejemplos:
            - "agenda" ‚Üí S√ç
            - "Quiero agendar una cita" ‚Üí S√ç
            - "¬øCu√°ndo puedo programar?" ‚Üí S√ç
            - "Disponibilidad para sesi√≥n" ‚Üí S√ç
            - "¬øA qu√© hora trabajan?" ‚Üí NO (solo pregunta horarios)
            - "¬øCu√°nto cuesta la consulta?" ‚Üí NO (pregunta precio)
            - "¬øQu√© incluye la sesi√≥n?" ‚Üí NO (pregunta informaci√≥n)
            """
            
            response = self.llm.invoke(prompt).content.strip().upper()
            
            if "S√ç" in response or "SI" in response:
                print(f"[DEBUG] LLM detect√≥ solicitud de agendamiento: {response}")
                return True
            else:
                print(f"[DEBUG] LLM NO detect√≥ solicitud de agendamiento: {response}")
                return False
                
        except Exception as e:
            print(f"[ERROR] Error en _detect_scheduling_request: {e}")
            # Fallback a detecci√≥n b√°sica por keywords cr√≠ticas
            scheduling_keywords = ['agendar', 'agenda', 'agendo', 'programar', 'cita', 'sesi√≥n', 'reuni√≥n']
            return any(keyword in user_input.lower() for keyword in scheduling_keywords)
    
    def _provide_calendar_link(self) -> str:
        """Proporciona el enlace del calendario para agendar citas."""
        return (
            f"¬°Perfecto! Para agendar tu sesi√≥n personalizada, entra a nuestro calendario online:\n\n"
            f"üóìÔ∏è {CALENDAR_LINK}\n\n"
            f"Ah√≠ puedes elegir el d√≠a y horario que mejor te convenga. "
            f"¬°Te esperamos!"
        )

    def _handle_continue_choice(self, user_input: str) -> str:
        """Maneja la respuesta del usuario despu√©s de _continue_conversation."""
        text_lower = user_input.lower().strip()
        
        # Opci√≥n 1: Quiere agente humano
        if any(x in text_lower for x in ["1", "uno", "humano", "ventas"]) or self._is_agent_request(user_input):
            return "Perfecto. Te conecto con un agente humano inmediatamente. Pauso este chat y un agente de ventas te contactar√° en este mismo canal."
        
        # Opci√≥n 2: Quiere seguir hablando
        elif any(x in text_lower for x in ["2", "dos", "seguir", "continuar", "hablar", "preguntas"]):
            return "Perfecto, sigamos hablando. ¬øQu√© preguntas tienes sobre nuestros servicios de potenciaci√≥n laboral?"
        
        # Si no detecta ninguna opci√≥n clara
        else:
            return (
                "No entend√≠ tu respuesta. Por favor elige:\n\n"
                "Escribe '1' para hablar con un agente humano\n"
                "Escribe '2' si quieres seguir hablando conmigo\n"
                "O escribe 'agente' para conectarte directamente."
            )

    def process_message(self, user_input, user_number: str = None):
        try:
            # PRIORIDAD M√ÅXIMA: Detectar solicitud de agente humano ANTES de cualquier procesamiento
            # Solo activar con palabra exacta "agente" o frases espec√≠ficas de solicitud
            if (user_input and self._is_agent_request(user_input) and 
                self.state != ConversationState.AWAITING_ROLE_INPUT):
                # Agregar el mensaje del usuario al historial antes de responder
                self.chat_history.append(HumanMessage(content=user_input))
                response = "Te conecto con un agente humano inmediatamente. Un agente de ventas te contactar√° en este mismo canal."
                self.chat_history.append(AIMessage(content=response))
                
                # Cambiar estado a HUMANO en Redis si tenemos chat_id
                if self.chat_id:
                    success = set_conversation_state_from_bot(self.chat_id, STATE_HUMANO, "CLIENTE_SOLICITA_AGENTE")
                    if success:
                        print(f"[BOT->REDIS] Estado cambiado a HUMANO para {self.chat_id}")
                    else:
                        print(f"[BOT->REDIS ERROR] No se pudo cambiar estado para {self.chat_id}")
                
                return response
            
            # SEGUNDA PRIORIDAD: Detectar solicitudes de agendamiento
            if user_input and self._detect_scheduling_request(user_input):
                # Agregar el mensaje del usuario al historial antes de responder
                self.chat_history.append(HumanMessage(content=user_input))
                response = self._provide_calendar_link()
                self.chat_history.append(AIMessage(content=response))
                return response
            
            # Los saludos iniciales no necesitan memoria ni RAG
            if self.state == ConversationState.AWAITING_GREETING:
                # Aplicar retraso con indicador de escritura
                self._apply_typing_delay(user_number)
                
                self.state = ConversationState.AWAITING_NAME_CITY
                prompt = "Act√∫as como Xtalento Bot. Genera un saludo inicial c√°lido y profesional que comience exactamente con la palabra '¬°Hola! üëã'. A continuaci√≥n, pres√©ntate brevemente y pide al usuario su nombre y la ciudad desde la que escribe. IMPORTANTE: Solo habla de servicios y informaci√≥n que tienes conocimiento confirmado en tu base de datos."
                response_text = self._generate_response(prompt)
                self.chat_history.append(AIMessage(content=response_text))
                return response_text

            # Guardamos la entrada del usuario en el historial
            self.chat_history.append(HumanMessage(content=user_input))

            if self.state == ConversationState.AWAITING_NAME_CITY:
                is_question = '?' in user_input or (user_input.lower().split() and user_input.lower().split()[0] in [
                    'qu√©', 'c√≥mo', 'cu√°ndo', 'd√≥nde', 'cu√°l', 'por', 'qui√©n', 'what', 
                    'how', 'when', 'where', 'which', 'why', 'who', 'do', 'is', 'are'
                ])
                if is_question:
                    print(f"[DEBUG] Se detect√≥ una pregunta en lugar de nombre/ciudad. Respondiendo sin interrumpir la conversaci√≥n.")
                    # Aplicar retraso con indicador de escritura
                    self._apply_typing_delay(user_number)
                    answer = self._safe_rag_answer(user_input)
                    self.chat_history.append(AIMessage(content=answer))
                    return answer
                
                self.user_data['name_city'] = user_input
                user_name = self._extract_name(user_input)
                self.user_data['name'] = user_name
                self.state = ConversationState.AWAITING_ROLE_INPUT
                
                # Aplicar retraso con indicador de escritura
                self._apply_typing_delay(user_number)
                
                prompt = f"Act√∫as como Xtalento Bot. El usuario se llama {user_name}. Dale una bienvenida personalizada (sin usar la palabra 'Hola') y luego preg√∫ntale sobre su cargo actual o al que aspira para poder darle una mejor asesor√≠a. IMPORTANTE: Solo habla de servicios que tienes conocimiento confirmado. Si no sabes algo espec√≠fico, di 'Actualmente no tengo conocimiento sobre esto. Si quieres comunicarte con un humano, menciona la palabra agente en el chat.'"
                response_text = self._generate_response(prompt)
                self.chat_history.append(AIMessage(content=response_text))
                return response_text

            elif self.state == ConversationState.AWAITING_ROLE_INPUT:
                role_classification = self._classify_role(user_input)
                if not role_classification:
                    print(f"[DEBUG] No se pudo clasificar el rol. Continuando sin clasificaci√≥n espec√≠fica.")
                    # En lugar de ir a _continue_conversation, continuar sin rol espec√≠fico
                    role_classification = 'general'  # Rol por defecto

                self.user_data['role'] = role_classification
                self.state = ConversationState.AWAITING_SERVICE_CHOICE
                
                # Aplicar retraso con indicador de escritura
                self._apply_typing_delay(user_number)
                
                prompt = f"""
                Act√∫as como Xtalento Bot. Presenta los siguientes servicios en una lista numerada sin mencionar ni revelar la categor√≠a/nivel del usuario:
                Gracias por tu inter√©s en Xtalento. Te contamos que ayudamos a personas como t√∫ a potenciar su perfil profesional y conseguir trabajo m√°s r√°pido.

                Nuestros servicios son:

                1. *Optimizaci√≥n de hoja de vida)(formato ATS)*: Adaptamos tu HV para que supere filtros digitales y capte la atenci√≥n de los reclutadores.
                2. *Mejora de perfil en plataformas de empleo*: Potenciamos tu perfil para que se vea profesional, tenga mayor visibilidad y atraiga m√°s oportunidades.
                3. *Preparaci√≥n de entrevistas laborales*: Te entrenamos con preguntas reales, retroalimentaci√≥n y t√©cnicas para responder con seguridad y generar impacto.
                4. *Estrategia personalizada de b√∫squeda de empleo)*: Creamos un plan contigo para que busques trabajo de forma m√°s efectiva, enfocada y con objetivos claros.
                5. *Simulaci√≥n de entrevistas laborales con feedback*: Simulaci√≥n de entrevistas reales, recomendaciones personalizadas y retroalimentaci√≥n para que te prepares mejor para la entrevista.
                6. *Metodo X (recomendado)*: Programa 1:1 de 5 sesiones para diagnosticar tu perfil, optimizar CV/LinkedIn, entrenarte en liderazgo y entrevistas, y cerrar con un plan de acci√≥n sostenible para ascender o moverte con estrategia.
                7. *Test EPI (Evaluaci√≥n de Personalidad Integral)*: Aplicamos el Test EPI (Evaluaci√≥n de Personalidad Integral), una herramienta dise√±ada para conocerte en profundidad y descubrir tu potencial personal y profesional.

                Libros y recursos en: https://xtalento.com.co

                Nota: escribe "Metodo X" en negrilla. Si el canal lo soporta, muestra la palabra "recomendado" en color gris junto al nombre; si no es posible, d√©jalo como (recomendado).
                Usa un emoji como üöÄ al final de la introducci√≥n.
                sin usar la palabra Hola de nuevo, recuerda que el usuario ya te salud√≥.
                Dile que puede elegir uno o varios servicios, marcando el n√∫mero del servicio y que si quiere escoger todos marque en el char la palabara Todos
                IMPORTANTE: Solo presenta estos servicios que tienes en tu conocimiento confirmado. Si el usuario pregunta por servicios no listados, di 'Actualmente no tengo conocimiento sobre esto. Si quieres comunicarte con un humano, menciona la palabra agente en el chat.'
                """
                response_text = self._generate_response(prompt)
                self.chat_history.append(AIMessage(content=response_text))
                return response_text

            elif self.state == ConversationState.AWAITING_SERVICE_CHOICE:
                # Usar LLM para detectar intenci√≥n de servicio
                service_detected = self._detect_service_intention(user_input)
                
                if not service_detected:
                    print(f"[DEBUG] No se detect√≥ intenci√≥n de servicio espec√≠fico. Usando RAG para responder.")
                    # En lugar de ir a _continue_conversation, usar RAG para responder naturalmente
                    answer = self._safe_rag_answer(user_input)
                    self.chat_history.append(AIMessage(content=answer))
                    return answer

                self.user_data['service'] = user_input
                self.state = ConversationState.PROVIDING_INFO
                
                # Si el usuario elige TODOS los servicios, ofrecer diagn√≥stico gratuito
                normalized_choice = (user_input or "").strip().lower()
                if normalized_choice in {"Todos", "Todos los servicios", "Lista completa", "Opciones disponibles"}:
                    response_text = (
                        "¬°Nos encantar√≠a conocerte y trabajar contigo! üéâ\n\n"
                        "Te ofrecemos un diagn√≥stico virtual gratuito para revisar tu perfil y a partir de este diagn√≥stico generar junto contigo una Estrategia Laboral Personalizada.\n\n"
                        "Marca 'agenda' en el chat para que escojas tu horario disponible ‚è∞"
                    )
                    self.chat_history.append(AIMessage(content=response_text))
                    return response_text
                
                # Si el usuario selecciona expl√≠citamente Metodo X, responder sin precios antes de construir el query general
                elif normalized_choice in {"metodo x", "m√©todo x", "metodo", "m√©todo", "6"}:
                    mx_prompt = (
                        "Usa EXCLUSIVAMENTE el contexto de tu conocimiento confirmado. Brinda informaci√≥n clara pero corta en un maximo de 200 tokens sobre 'Metodo X' SIN INCLUIR precios: "
                        "qu√© es, para qui√©n aplica, beneficios, c√≥mo funciona y resultados esperables. "
                        "IMPORTANTE: Solo habla de informaci√≥n que tienes confirmada en tu base de conocimiento. Si no tienes conocimiento suficiente sobre alg√∫n aspecto del M√©todo X, di 'Actualmente no tengo conocimiento completo sobre esto. Si quieres comunicarte con un humano, menciona la palabra agente en el chat.' "
                        f"Cierra invitando a agendar una asesor√≠a personalizada gratuita. Incluye este enlace para agendar: {CALENDAR_LINK}. Recuerda que si el cliente dice que le interesa o quiere agendar una asesoria no le digas nada sobre pagos porque esta asesoria es gratuita"
                    )
                    mx_answer = self._safe_rag_answer(mx_prompt)
                    self.chat_history.append(AIMessage(content=mx_answer))
                    return mx_answer

                # PASO 1: Enviar mensaje de diagn√≥stico gratuito primero
                # Aplicar retraso con indicador de escritura
                self._apply_typing_delay(user_number)
                
                diagnostic_message = (
                    f"¬°Nos encantar√≠a conocerte y trabajar contigo! üéâ\n\n"
                    f"Te ofrecemos un diagn√≥stico virtual (sin costo) para revisar tu perfil y a partir de este diagn√≥stico generar junto contigo una Estrategia Laboral Personalizada.\n\n"
                    f"Separa un espacio en el siguiente link:\n"
                    f"üóìÔ∏è {CALENDAR_LINK}\n\n"
                    f"A continuaci√≥n te comparto la informaci√≥n detallada del servicio que seleccionaste: üëá"
                )
                self.chat_history.append(AIMessage(content=diagnostic_message))
                
                # PASO 2: Esperar un poco m√°s antes del segundo mensaje (informaci√≥n detallada)
                self._apply_typing_delay(user_number)
                
                # PASO 3: Enviar informaci√≥n detallada con precios
                user_role = self.user_data.get('role', 't√°ctico')

                query = (
                    f"""
                    Usa EXCLUSIVAMENTE el contexto de tu conocimiento confirmado para responder, excepto en la pol√≠tica de precios indicada abajo.
                    Servicios escogidos por el usuario: "{user_input}".

                    üö® POL√çTICA DE CONOCIMIENTO ESTRICTA:
                    - SOLO proporciona informaci√≥n que tienes confirmada en tu base de conocimiento.
                    - Si no tienes informaci√≥n completa sobre alg√∫n servicio solicitado, di: "Actualmente no tengo conocimiento completo sobre este servicio. Si quieres comunicarte con un humano, menciona la palabra 'agente' en el chat."
                    - NO inventes detalles sobre servicios, tiempos o caracter√≠sticas.
                    - NUNCA reveles o menciones la clasificaci√≥n de nivel del usuario.

                    üìä POL√çTICA DE PRECIOS POR NIVEL JER√ÅRQUICO:
                    
                    Para el nivel OPERATIVO (cargos de ejecuci√≥n directa y t√©cnicos: analistas, desarrolladores, asistentes, operarios, t√©cnicos, especialistas junior, consultores junior, ejecutivos de cuenta, vendedores):
                    - Hoja de vida/CV/ATS: 50.000$ (precio fijo)
                    - Mejora de perfil en plataformas: 80.000$ (precio fijo)  
                    - Para otros servicios: busca en tu base de conocimiento los precios espec√≠ficos para nivel operativo
                    
                    Para el nivel T√ÅCTICO (cargos de supervisi√≥n y coordinaci√≥n media: coordinadores, especialistas senior, jefes de √°rea, supervisors, team leads, l√≠deres de equipo, gerentes de √°rea espec√≠fica):
                    - Hoja de vida/CV/ATS: 50.000$ (precio fijo)
                    - Mejora de perfil en plataformas: 80.000$ (precio fijo)
                    - Para otros servicios: busca en tu base de conocimiento los precios espec√≠ficos para nivel t√°ctico
                    
                    Para el nivel ESTRAT√âGICO (cargos de alta direcci√≥n y toma de decisiones: CEO, presidente, vicepresidente, director general, directores de √°rea, gerentes generales, VP, fundadores):
                    - Hoja de vida/CV/ATS: 50.000$ (precio fijo)
                    - Mejora de perfil en plataformas: 80.000$ (precio fijo)
                    - Para otros servicios: busca en tu base de conocimiento los precios espec√≠ficos para nivel estrat√©gico
                    
                    El usuario est√° clasificado como nivel {user_role.upper()}. Busca los precios correspondientes a este nivel en tu base de conocimiento, excepto para los dos servicios con precio fijo mencionados arriba.
                  
                    Formato de salida (en espa√±ol, claro y consistente). Sigue estos encabezados en este orden, en texto plano:
                    
                    Servicio o servicios escogidos: <lista breve de los servicios tal como aparecen en el contexto>
                    Informaci√≥n sobre el servicio o servicios: <qu√© incluye, c√≥mo funciona y tiempos si est√°n en contexto - SOLO si tienes la informaci√≥n confirmada>
                    Precio del servicio o servicios: <aplica precios espec√≠ficos para nivel {user_role} seg√∫n tu base de conocimiento, excepto hoja de vida=50.000$ y mejora de perfil=80.000$ que son fijos>
                    
                    - Paso 1: llenar el formulario {PAYMENT_FORM_URL} (indica que este paso es fundamental para poder seguir)

                    - Paso 2: SOLO si entre los servicios hay 'hoja de vida'/'cv'/'curr√≠culum'/'ATS'/'1'/Hoja de vida/ Hoja/ hoja/Elaboraci√≥n: pedir la hoja de vida actual; si no la tiene, pedir documento con nombres, c√©dula, estudios y experiencias laborales. Si NO aplica, escribe: 'paso 2: (no aplica)'

                    - Paso 3: formas de pagar y confirmar pago: incluye las cuentas/medios de pago que estan en el RAG SI no ac√° est√°n Banco: bancolmbia \n tipo: ahorros \n numero: 10015482343 \n titular: gina paola cano \n nequi: 3128186587.

                    Cierra indicando: 'Confirma cuando completes el formulario (paso 1) y cuando realices el pago (paso 3)'. Evita saludos iniciales. Por favor trata de no sobrepasar los 400 tokens.
                    """
                )
                answer = self._safe_rag_answer(query)
                self.chat_history.append(AIMessage(content=answer))
                
                # Retornar ambos mensajes concatenados para el sistema de logging
                return f"{diagnostic_message}\n\n{answer}"
            
            elif self.state == ConversationState.AWAITING_CONTINUE_CHOICE:
                # PRIORIDAD 1: Verificar si es un cliente retomando despu√©s de agente humano
                if self._is_returning_after_agent(user_input):
                    print(f"[DEBUG] Detectado cliente retomando conversaci√≥n despu√©s de agente.")
                    # Cambiar a estado de informaci√≥n y dar bienvenida c√°lida
                    self.state = ConversationState.PROVIDING_INFO
                    welcome_message = self._generate_welcome_back_message(user_input)
                    self.chat_history.append(AIMessage(content=welcome_message))
                    return welcome_message
                
                # PRIORIDAD 2: Verificar si es una conversaci√≥n natural (retomar despu√©s de pausa)
                elif self._is_natural_conversation_resumption(user_input):
                    print(f"[DEBUG] Detectado retomar conversaci√≥n natural. Reseteando flujo.")
                    # Resetear el flujo como si fuera una nueva conversaci√≥n
                    self.state = ConversationState.PROVIDING_INFO
                    answer = self._safe_rag_answer(user_input)
                    self.chat_history.append(AIMessage(content=answer))
                    return answer
                else:
                    # Manejar como elecci√≥n 1/2/agente
                    response_text = self._handle_continue_choice(user_input)
                    self.chat_history.append(AIMessage(content=response_text))
                    
                    # Si el usuario eligi√≥ agente, mantener el estado para que el webhook detecte el bloqueo
                    if "Te conecto con un agente humano" in response_text:
                        return response_text
                    # Si eligi√≥ seguir hablando, cambiar a estado de informaci√≥n
                    elif "¬øQu√© preguntas tienes" in response_text:
                        self.state = ConversationState.PROVIDING_INFO
                        return response_text
                    # Si no entendi√≥, mantener el mismo estado para volver a preguntar
                    else:
                        return response_text
                
            elif self.state == ConversationState.PROVIDING_INFO:
                # PRIORIDAD 1: Verificar si es un cliente retomando despu√©s de agente humano
                if self._is_returning_after_agent(user_input):
                    print(f"[DEBUG] Detectado cliente retomando conversaci√≥n despu√©s de agente en PROVIDING_INFO.")
                    welcome_message = self._generate_welcome_back_message(user_input)
                    self.chat_history.append(AIMessage(content=welcome_message))
                    return welcome_message
                
                # PRIORIDAD 2: Detectar confirmaci√≥n de pasos 1 y 3 usando memoria persistente
                payment_status = self._detect_payment_confirmation(user_input)
                
                # Actualizar memoria de confirmaciones
                if payment_status['paso1']:
                    self.confirmed_steps['paso1'] = True
                    print(f"[DEBUG] Actualizando memoria: Paso 1 confirmado")
                
                if payment_status['paso3']:
                    self.confirmed_steps['paso3'] = True
                    print(f"[DEBUG] Actualizando memoria: Paso 3 confirmado")
                
                # Verificar si ambos pasos est√°n confirmados (usando memoria)
                if self.confirmed_steps['paso1'] and self.confirmed_steps['paso3']:
                    response_text = self._send_calendar_for_confirmed_payment()
                    self.chat_history.append(AIMessage(content=response_text))
                    return response_text
                
                # Manejo de confirmaciones individuales usando memoria
                elif payment_status['paso1'] and not self.confirmed_steps['paso3']:
                    response_text = (
                        "¬°Confirmado! ‚úÖ Has completado el formulario (paso 1).\n\n"
                        "Ahora te falta completar el paso 3 (realizar Y COMPLETAR el pago/transferencia) para poder agendar tu sesi√≥n virtual.\n\n"
                        "‚ö†Ô∏è **IMPORTANTE:** Solo conf√≠rmalo cuando YA hayas terminado de hacer el pago completamente.\n\n"
                        "‚úÖ **Confirma SOLO cuando hayas completado el pago:**\n"
                        "‚Ä¢ 'Realic√© el pago'\n"
                        "‚Ä¢ 'Ya pagu√©'\n"
                        "‚Ä¢ 'Termin√© la transferencia'\n"
                        "‚Ä¢ 'Pago completado'\n\n"
                        "‚ùå **NO confirmes si solo vas a pagar o tienes preguntas.**\n\n"
                        "Una vez COMPLETADO el pago, conf√≠rmalo y te enviar√© inmediatamente el link del calendario. üòä"
                    )
                    self.chat_history.append(AIMessage(content=response_text))
                    return response_text
                
                elif payment_status['paso3'] and not self.confirmed_steps['paso1']:
                    response_text = (
                        "¬°Confirmado! ‚úÖ Has completado el pago (paso 3).\n\n"
                        "Ahora te falta completar el paso 1 (llenar Y ENVIAR completamente el formulario) para poder agendar tu sesi√≥n virtual.\n\n"
                        "‚ö†Ô∏è **IMPORTANTE:** Solo conf√≠rmalo cuando YA hayas terminado de llenar y enviar el formulario.\n\n"
                        "‚úÖ **Confirma SOLO cuando hayas completado el formulario:**\n"
                        "‚Ä¢ 'Complet√© el formulario'\n"
                        "‚Ä¢ 'Ya llen√© el formulario'\n"
                        "‚Ä¢ 'Envi√© el formulario'\n"
                        "‚Ä¢ 'Formulario terminado'\n\n"
                        "‚ùå **NO confirmes si solo vas a llenarlo o tienes preguntas.**\n\n"
                        "Una vez COMPLETADO el formulario, conf√≠rmalo y te enviar√© inmediatamente el link del calendario. üòä"
                    )
                    self.chat_history.append(AIMessage(content=response_text))
                    return response_text
                
                # Si ya confirm√≥ pasos previamente, record√°rselo
                elif (self.confirmed_steps['paso1'] and not payment_status['paso3'] and 
                      not self.confirmed_steps['paso3']):
                    response_text = (
                        "Recuerda que ya confirmaste el formulario ‚úÖ\n\n"
                        "Solo falta que confirmes el PAGO cuando ya lo hayas completado:\n"
                        "‚Ä¢ 'Realic√© el pago'\n"
                        "‚Ä¢ 'Ya pagu√©'\n"
                        "‚Ä¢ 'Pago completado'\n\n"
                        "Una vez confirmes el pago, te env√≠o el calendario inmediatamente. üòä"
                    )
                    self.chat_history.append(AIMessage(content=response_text))
                    return response_text
                    
                elif (self.confirmed_steps['paso3'] and not payment_status['paso1'] and 
                      not self.confirmed_steps['paso1']):
                    response_text = (
                        "Recuerda que ya confirmaste el pago ‚úÖ\n\n"
                        "Solo falta que confirmes el FORMULARIO cuando ya lo hayas completado:\n"
                        "‚Ä¢ 'Complet√© el formulario'\n"
                        "‚Ä¢ 'Ya llen√© el formulario'\n"
                        "‚Ä¢ 'Formulario terminado'\n\n"
                        "Una vez confirmes el formulario, te env√≠o el calendario inmediatamente. üòä"
                    )
                    self.chat_history.append(AIMessage(content=response_text))
                    return response_text
                
                # Opci√≥n espec√≠fica SOLO para cuando el usuario expl√≠citamente quiere ver la lista completa
                text_l = (user_input or "").strip().lower()
                
                # Usar LLM para detectar si quiere ver la lista de servicios
                if self._wants_to_see_services_list(user_input):
                    response_text = (
                        "Perfecto, sigamos. Te recuerdo nuestros servicios disponibles:\n\n"
                        "1. Optimizaci√≥n de Hoja de Vida (ATS)\n"
                        "2. Mejora de perfil en plataformas de empleo\n"
                        "3. Preparaci√≥n para Entrevistas\n"
                        "4. Estrategia de b√∫squeda de empleo\n"
                        "5. Simulaci√≥n de entrevista con feedback\n"
                        "6. **M√©todo X** (recomendado)\n"
                        "7. Test EPI (Evaluaci√≥n de Personalidad Integral)\n\n"
                        "¬øCu√°l te interesa? Puedes elegir por n√∫mero o nombre del servicio."
                    )
                    self.chat_history.append(AIMessage(content=response_text))
                    return response_text

                # Si menciona temas de pago/formulario pero no confirma claramente, pedir clarificaci√≥n
                if self._is_payment_related_query(user_input):
                    response_text = self._send_step_clarification_message()
                    self.chat_history.append(AIMessage(content=response_text))
                    return response_text

                # Responder v√≠a RAG; si RAG no sabe, devolver opciones 1/2
                answer = self._safe_rag_answer(user_input)
                self.chat_history.append(AIMessage(content=answer))
                return answer

        except Exception as e:
            print(f"\n[ERROR] Ha ocurrido un problema, continuo la conversaci√≥n: {e}")
            guidance = "hubo un inconveniente interno; responde de forma √∫til a lo √∫ltimo que dijo el usuario y mant√©n la conversaci√≥n en marcha. IMPORTANTE: Solo habla de informaci√≥n que tienes conocimiento confirmado. Si no sabes algo espec√≠fico, di 'Actualmente no tengo conocimiento sobre esto. Si quieres comunicarte con un humano, menciona la palabra agente en el chat.'"
            return self._continue_conversation(str(user_input), guidance)

    def _detect_payment_confirmation(self, user_input: str) -> dict:
        """Usa LLM para detectar si el usuario REALMENTE confirma haber completado el formulario y/o realizado el pago."""
        try:
            prompt = f"""
            Analiza MUY CUIDADOSAMENTE si el usuario est√° CONFIRMANDO COMPLETAMENTE haber realizado estas acciones espec√≠ficas:

            PASO 1: LLENAR Y ENVIAR completamente un formulario de Google Forms
            PASO 3: REALIZAR Y COMPLETAR un pago/transferencia bancaria

            MENSAJE DEL USUARIO: "{user_input}"

            CRITERIOS ESTRICTOS:
            
            Para PASO1=S√ç (formulario):
            - Debe confirmar que YA llen√≥/complet√≥/envi√≥/termin√≥ el formulario
            - Debe usar verbos de completitud: "complet√©", "llen√©", "envi√©", "termin√©", "ya hice"
            - NO confirmar si solo dice "voy a llenar", "necesito llenar", "¬øc√≥mo lleno?"
            
            Para PASO3=S√ç (pago):
            - Debe confirmar que YA realiz√≥/hizo/envi√≥/complet√≥ el pago/transferencia
            - Debe usar verbos de completitud: "realic√©", "pagu√©", "transfer√≠", "ya hice", "envi√©"
            - NO confirmar si solo dice "voy a pagar", "necesito pagar", "¬øc√≥mo pago?"

            Responde en formato exacto:
            PASO1: S√ç/NO
            PASO3: S√ç/NO

            Ejemplos CORRECTOS:
            - "Ya complet√© el formulario" ‚Üí PASO1: S√ç, PASO3: NO
            - "Realic√© el pago" ‚Üí PASO1: NO, PASO3: S√ç
            - "Termin√© el formulario y pagu√©" ‚Üí PASO1: S√ç, PASO3: S√ç
            - "Listo, envi√© el formulario" ‚Üí PASO1: S√ç, PASO3: NO

            Ejemplos INCORRECTOS (NO confirmar):
            - "Voy a llenar el formulario" ‚Üí PASO1: NO, PASO3: NO (futuro, no completado)
            - "¬øC√≥mo pago?" ‚Üí PASO1: NO, PASO3: NO (pregunta, no confirmaci√≥n)
            - "Necesito hacer el pago" ‚Üí PASO1: NO, PASO3: NO (necesidad, no completitud)
            - "El formulario est√° dif√≠cil" ‚Üí PASO1: NO, PASO3: NO (comentario, no confirmaci√≥n)
            - "¬øD√≥nde est√° el formulario?" ‚Üí PASO1: NO, PASO3: NO (pregunta ubicaci√≥n)
            """
            
            response = self.llm.invoke(prompt).content.strip().upper()
            print(f"[DEBUG] LLM respuesta ESTRICTA de confirmaci√≥n: {response}")
            
            # Extraer respuestas
            paso1_confirmed = "PASO1: S√ç" in response or "PASO1: SI" in response
            paso3_confirmed = "PASO3: S√ç" in response or "PASO3: SI" in response
            
            print(f"[DEBUG] Confirmaciones ESTRICTAS detectadas - Paso1: {paso1_confirmed}, Paso3: {paso3_confirmed}")
            
            return {
                'paso1': paso1_confirmed,
                'paso3': paso3_confirmed,
                'both_confirmed': paso1_confirmed and paso3_confirmed
            }
                
        except Exception as e:
            print(f"[ERROR] Error en _detect_payment_confirmation: {e}")
            # Fallback M√ÅS ESTRICTO con keywords de completitud √∫nicamente
            text_lower = user_input.lower().strip()
            
            # Solo keywords que indican COMPLETITUD, no intenci√≥n
            paso1_keywords = ['complet√© el formulario', 'llen√© el formulario', 'envi√© el formulario', 'termin√© el formulario', 'formulario listo', 'formulario enviado']
            paso3_keywords = ['realic√© el pago', 'hice el pago', 'pagu√©', 'transfer√≠', 'pago listo', 'pago realizado', 'ya pagu√©']
            
            paso1_confirmed = any(keyword in text_lower for keyword in paso1_keywords)
            paso3_confirmed = any(keyword in text_lower for keyword in paso3_keywords)
            
            return {
                'paso1': paso1_confirmed,
                'paso3': paso3_confirmed,
                'both_confirmed': paso1_confirmed and paso3_confirmed
            }
    
    def _send_calendar_for_confirmed_payment(self) -> str:
        """Env√≠a el link del calendario cuando se confirman ambos pasos."""
        return (
            f"¬°Excelente! ‚úÖ Has completado tanto el formulario como el pago.\n\n"
            f"Ahora puedes agendar tu sesi√≥n virtual de 60 minutos directamente en nuestro calendario:\n\n"
            f"üóìÔ∏è {CALENDAR_LINK}\n\n"
            f"Elige el d√≠a y horario que mejor te convenga. Una vez agendado, recibir√°s los detalles de confirmaci√≥n.\n\n"
            f"¬°Estamos listos para acompa√±arte en este proceso! üòä"
        )

    def _reset_confirmation_memory(self):
        """Resetea la memoria de confirmaciones de pasos."""
        self.confirmed_steps = {
            'paso1': False,
            'paso3': False
        }
        print(f"[DEBUG] Memoria de confirmaciones reseteada")

    def _get_confirmation_status_summary(self) -> str:
        """Retorna un resumen del estado actual de confirmaciones."""
        status_paso1 = "‚úÖ" if self.confirmed_steps['paso1'] else "‚è≥"
        status_paso3 = "‚úÖ" if self.confirmed_steps['paso3'] else "‚è≥"
        return f"Estado: Formulario {status_paso1} | Pago {status_paso3}"

    def _wants_to_see_services_list(self, user_input: str) -> bool:
        """Usa LLM para detectar si el usuario quiere ver la lista completa de servicios."""
        try:
            prompt = f"""
            Analiza si el siguiente mensaje del usuario indica que quiere VER, MOSTRAR o CONOCER la lista completa de servicios disponibles.

            MENSAJE DEL USUARIO: "{user_input}"

            ¬øEl usuario est√° pidiendo espec√≠ficamente ver la lista de servicios disponibles?

            Responde √öNICAMENTE:
            - "S√ç" si claramente quiere ver/mostrar/conocer todos los servicios o la lista completa
            - "NO" si pregunta sobre un servicio espec√≠fico, precio, o hace otra consulta

            Ejemplos:
            - "Mostrar servicios" ‚Üí S√ç
            - "¬øQu√© servicios tienen?" ‚Üí S√ç
            - "Lista completa" ‚Üí S√ç
            - "Ver opciones disponibles" ‚Üí S√ç
            - "¬øCu√°nto cuesta la hoja de vida?" ‚Üí NO (pregunta espec√≠fica)
            - "Quiero el m√©todo X" ‚Üí NO (selecci√≥n espec√≠fica)
            - "¬øC√≥mo funciona?" ‚Üí NO (pregunta general)
            """
            
            response = self.llm.invoke(prompt).content.strip().upper()
            
            if "S√ç" in response or "SI" in response:
                print(f"[DEBUG] LLM detect√≥ solicitud de lista de servicios: {response}")
                return True
            else:
                print(f"[DEBUG] LLM NO detect√≥ solicitud de lista de servicios: {response}")
                return False
                
        except Exception as e:
            print(f"[ERROR] Error en _wants_to_see_services_list: {e}")
            # Fallback a detecci√≥n b√°sica por keywords
            service_list_keywords = ['mostrar servicios', 'ver servicios', 'lista de servicios', 'que servicios', 'opciones disponibles']
            return any(keyword in user_input.lower() for keyword in service_list_keywords)

    def _is_payment_related_query(self, user_input: str) -> bool:
        """Usa LLM para detectar si el usuario est√° haciendo consultas sobre pagos/pasos pero no confirmando."""
        try:
            prompt = f"""
            Analiza si el siguiente mensaje del usuario est√° haciendo una CONSULTA o PREGUNTA sobre:
            - Formularios, pasos, pagos, transferencias
            - Informaci√≥n sobre c√≥mo pagar, d√≥nde pagar, precios
            - Datos bancarios, cuentas, m√©todos de pago
            - Proceso de completar formularios

            Pero NO est√° confirmando haber completado algo.

            MENSAJE DEL USUARIO: "{user_input}"

            ¬øEs una consulta/pregunta sobre temas de pago o formularios (pero no una confirmaci√≥n)?

            Responde √öNICAMENTE:
            - "S√ç" si pregunta sobre pagos/formularios pero no confirma
            - "NO" si no es relacionado con pagos/formularios, o si est√° confirmando

            Ejemplos:
            - "¬øC√≥mo pago?" ‚Üí S√ç (pregunta sobre pago)
            - "¬øD√≥nde est√° el formulario?" ‚Üí S√ç (pregunta sobre formulario)
            - "Ya pagu√©" ‚Üí NO (es confirmaci√≥n, no pregunta)
            - "¬øQu√© servicios tienen?" ‚Üí NO (no relacionado con pagos)
            - "Informaci√≥n sobre precios" ‚Üí S√ç (pregunta sobre pagos)
            """
            
            response = self.llm.invoke(prompt).content.strip().upper()
            
            if "S√ç" in response or "SI" in response:
                print(f"[DEBUG] LLM detect√≥ consulta de pago: {response}")
                return True
            else:
                print(f"[DEBUG] LLM NO detect√≥ consulta de pago: {response}")
                return False
                
        except Exception as e:
            print(f"[ERROR] Error en _is_payment_related_query: {e}")
            # Fallback a detecci√≥n b√°sica por keywords
            query_keywords = ['formulario', 'pago', 'paso', 'transferencia', 'banco', 'cuenta', 'c√≥mo pago', 'precio']
            return any(keyword in user_input.lower() for keyword in query_keywords)
    
    def _send_step_clarification_message(self) -> str:
        """Mensaje para clarificar los pasos cuando el usuario no confirma claramente."""
        # Mostrar estado actual de confirmaciones
        status_paso1 = "‚úÖ COMPLETADO" if self.confirmed_steps['paso1'] else "‚è≥ PENDIENTE"
        status_paso3 = "‚úÖ COMPLETADO" if self.confirmed_steps['paso3'] else "‚è≥ PENDIENTE"
        
        return (
            f"**ESTADO ACTUAL DE TUS PASOS:**\n"
            f"üìã **Paso 1 (Formulario):** {status_paso1}\n"
            f"üí≥ **Paso 3 (Pago):** {status_paso3}\n\n"
            f"Para poder enviarte el calendario, necesito que confirmes √öNICAMENTE cuando hayas COMPLETADO totalmente cada paso:\n\n"
            f"üìã **Paso 1:** Llenar Y ENVIAR el formulario de Google Forms\n"
            f"üí≥ **Paso 3:** Realizar Y COMPLETAR el pago/transferencia\n\n"
            f"‚ö†Ô∏è **IMPORTANTE:** Solo confirma cuando ya hayas terminado completamente la acci√≥n.\n\n"
            f"‚úÖ **Ejemplos de confirmaci√≥n v√°lida:**\n"
            f"‚Ä¢ 'Ya complet√© el formulario'\n"
            f"‚Ä¢ 'Realic√© el pago'\n"
            f"‚Ä¢ 'Termin√© el formulario y pagu√©'\n"
            f"‚Ä¢ 'Listo, envi√© el formulario'\n\n"
            f"Si necesitas ayuda personalizada, escribe **'agente'** para comunicarte con un agente de ventas. üë•"
        )


# --- Funciones de Soporte ---
def load_documents():
    """Carga los documentos desde el directorio especificado."""
    loader = DirectoryLoader(DOCUMENTS_PATH, glob="**/*.*", loader_cls=lambda p: UnstructuredFileLoader(p))
    return loader.load()

def create_vector_store(documents):
    """Crea y guarda el almac√©n de vectores FAISS."""
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=CHUNK_SIZE, chunk_overlap=CHUNK_OVERLAP)
    docs = text_splitter.split_documents(documents)
    embeddings = OpenAIEmbeddings()
    vectorstore = FAISS.from_documents(docs, embeddings)
    vectorstore.save_local(VECTORSTORE_PATH)
    return vectorstore

def load_vector_store():
    """Carga el almac√©n de vectores FAISS si existe."""
    if os.path.exists(VECTORSTORE_PATH):
        embeddings = OpenAIEmbeddings()
        return FAISS.load_local(VECTORSTORE_PATH, embeddings, allow_dangerous_deserialization=True)
    return None

def main():
    """Funci√≥n principal para ejecutar el chatbot."""
    if not os.getenv("OPENAI_API_KEY"):
        print("[ERROR] La variable de entorno OPENAI_API_KEY no fue encontrada.")
        print("Por favor, aseg√∫rate de tener un archivo .env en la ra√≠z del proyecto con la l√≠nea: OPENAI_API_KEY='tu_clave_aqui'")
        return

    vectorstore = load_vector_store()
    if not vectorstore:
        print("Creando almac√©n de vectores por primera vez...")
        documents = load_documents()
        vectorstore = create_vector_store(documents)
        print("Almac√©n de vectores creado y guardado.")

    chatbot = Chatbot(vectorstore)
    
    print(f"Xtalento: {chatbot.process_message(None)}")
    
    while True:
        user_input = input("\nT√∫: ")
        if user_input.lower() == 'salir':
            print("¬°Hasta luego!")
            break
        
        response = chatbot.process_message(user_input)
        print(f"\nXtalento: {response}")

if __name__ == "__main__":
    main()
